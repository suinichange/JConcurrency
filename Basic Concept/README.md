# Overview

### 并发，同步，异步，进程，线程相关概念

[1.1 操作系统的演进](#11操作系统的演进)

[1.2 操作系统的基本特性之并发，共享，异步](#12操作系统的基本特性之并发共享异步)

[1.3 进程的基本状态及转换](#13进程的基本状态及转换)

[1.4 进程同步](#14进程同步)

[1.5 同步问题之生产者-消费者及临界区](#15同步问题之生产者-消费者及临界区)

[1.6 进程通信](#16进程通信)

[1.7 线程基本概念](#17线程基本概念)

### 锁相关概念

[2.1 死锁的产生与处理](#21死锁的产生与处理)

[2.2 死锁的预防与避免](#22死锁的预防与避免)

[2.3 死锁的检测与解除](#23死锁的检测与解除)

[2.4 自旋锁](#24自旋锁)

[2.5 读-拷贝-修改锁(RCU锁)](#25读-拷贝-修改锁RCU锁)

## 1.1操作系统的演进

### 未配置操作系统的计算机

　　人工操作：程序员将写好的程序（纸带），装入纸带输入机，再启动输入机将程序输入计算机，计算机再运行。（联机IO）

　　缺点：用户独占全机；CPU等待纸带装机，大部分时间CPU和内存是空闲的；

　　演进：脱机IO，使用一个外围机先把数据输入好到磁带，再使用CPU进行计算。输出时先输出到磁带，再交由外围机输出结果。

　　改进后的效果：减少CPU空闲；提高了IO速度。


### 单道批处理系统

　　单道批处理系统：把一批作业输入到磁带，再交由系统监督程序进行控制，使得这批程序能一个接一个的连续处理。但是**内存一次只能处理一个作业**，处理完成后再将控制权交由监督程序，再由它将下一个作业调入内存。

　　缺点：系统中资源得不到充分利用。程序在处理IO请求时，CPU空闲，需要等待程序IO完成后才能继续运行。

　　演进：多道批处理系统


### 多道批处理系统

　　多道批处理系统：将用户提交的作业先存放到外存，并排成一个后备队列。然后作业调度算法从队列中选取**若干作业调入内存**，使他们共享CPU和系统资源。这样内存中有若干道程序，这样运行A程序IO请求，导致CPU空闲时。可以调度B程序使用CPU进行运算，以此类推，充分利用计算机资源。

　　优点：资源利用率高；系统吞吐量大。

　　缺点：平均作业周转时间长，由于作业要排队依次处理，那么一个作业完成的时间会变长；**无交互能力**，用户一旦将作业交由系统处理，直至作业完成，用户都不能和作业进行交互，都是计算机系统自己在进行调度。（ps：作业周转时间=作业完成时间-作业提交时间）


### 分时系统

　　要满足的需求：人机能够交互；共享主机；

　　分时系统：一台主机连接了多个显示器和键盘的终端所组成的系统，该系统允许多个用户通过自己的终端和计算机进行交互，共享主机中的资源。

　　人机交互的实现：即用户输入命令后，能对自己的作业的运行及时的实施控制，或进行修改。

　　1. 作业直接进入内存。而不是先存放在外存，再进行排队调度。

　　2. 采用轮转的运行方式。系统规定每个作业只能运行一个时间片（一个时间片，就是一段很短的时间，如：30ms），然后就暂停该作业运行，并立即调度下一个作业运行。如果在不长时间内使所有作业都执行一个时间片，便可以使每个用户都能及时与自己的作业交互，并得到及时响应。

## 1.2操作系统的基本特性之并发，共享，异步

### 并发

#### 并行与并发

　　并行性：两个或多个事件在同一时间发生。（物理上的同时发生）

　　并发性：两个或多个事件在同一时间间隔发生。（逻辑上的同时发生）

　　在单CPU系统中，每一时刻只能执行一道程序，比如0~30ms执行A程序，30~60ms执行B程序。因此从宏观上来讲，在1秒钟的时间间隔内这两道程序是同时运行的，但实际上这两个程序是交替运行的。

　　而在多CPU系统，这些程序则可以分配给多个CPU处理，实现并行执行。即每个CPU处理一道程序，这样多个程序就能同时执行。

#### 引入进程

　　在为引入进程的系统中，在属于同一个应用程序的计算程序和IO处理程序只能顺序执行。但如果把计算程序，IO处理程序分别建一个进程，这两个进程便可并发执行。若对内存内的多个程序分别建立一个进程，他们就可以并发执行。这样便能极大提高资源的利用率和系统的吞吐量。

　　所谓进程，是指系统中能独立运行并作为资源分配和调度的基本单位。
### 共享

　　在OS环境下的资源共享或称为资源复用，是指系统中的资源**可供内存中多个并发
执行的进程共同使用**。对于这种资源共享方式，其管理就要复杂得多，因为系统中的**资源远少于多道程序需求的总和**，会形成它们对共享资源的争夺。

　　资源共享的两种方式：

　　1. 互斥共享：系统中的某些资源，如打印机、磁带机（临界资源）等，虽然可以提供给多个进程（线程）使用，但在同一段时间内只允许一个进程访问该资源（互斥访问）。

　　当进程A要访问某资源时，必须先提出请求。若此时该资源空闲，系统便可将之分配给请求进程A使用。此后若再有其它进程也要访问该资源，只要A未用完就必须等待。仅当A进程访问完并释放系统资源后，才允许另一进程对该资源进行访问。
　　

　　2. 同时访问：系统中还有另一类资源，允许在一段时间内由多个进程“同时”对它们进行访问。典型的可供多个进程“同时”访问的资源是磁盘设备。一些用重入码编写的文件也可以被“同时”共享，即允许若个用户同时访问该文件。

### 异步
　　在单处理机环境下，由于系统中只有一台处理机，因而每次只允许一个进程执行，其余进程只能等待。当正在执行的进程提出某种资源要求时，如打印请求，而此时打印机正在为其它进程打印，由于打印机属于临界资源，因此正在执行的进程必须等待，并释放出处理机，直到打印机空闲，并再次获得处理机时，该进程方能继续执行。可见，由于资源等因素的限制，进程的执行通常都不可能“一气呵成”，而是以“停停走走”的方式运行。

　　对于内存中的每个进程，在何时能获得处理机运行，何时又因提出某种资源请求而暂停，以及进程以怎样的速度向前推进，每道程序总共需要多少时间才能完成等等，都是不可预知的。**进程是以人们不可预知的速度向前推进的，此即进程的异步性**。

　　尽管如此，但只要在OS中配置有完善的进程同步机制，且运行环境相同，则作业即便经过多次运行，也都会获得完全相同的结果。因此异步运行方式是允许的，而且是操作系统的一个重要特征。

## 1.3进程的基本状态及转换

### 进程的基本状态

　　创建状态：进程刚被创建，但未获取到所需资源（如内存），无法被直接调度运行的状态。

　　就绪状态：进程已经准备好运行的状态，已分配到除CPU外的必要资源，只要获取CPU便可立即执行。

　　执行状态：进程已获得CPU，其程序正在执行的状态。

　　阻塞状态：正在执行的进程由于发生某事件（如 IO请求、申请缓冲区失败等）暂时无法继续执行时的状态。

　　终止状态：进程执行完毕或者因异常，操作系统终结，被其它进程终结等原因结束的状态。

### 进程状态间的转换

  ![进程状态间的转换](https://github.com/suinichange/JConcurrency/blob/master/Basic%20Concept/%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81%E9%97%B4%E7%9A%84%E8%BD%AC%E6%8D%A2.jpg)

### 挂起操作——为什么需要挂起？

　　终端用户需要：用户想暂停自己运行的程序，查看起执行情况或对其进行修改。

　　父进程请求：父进程希望挂起子进程以查看子进程状态或是协调子进程间的活动。

　　负荷调节的需要：负荷过重时，系统希望把一些不重要的进程挂起以保证系统正常运行。

　　操作系统需要：系统希望挂起某些进程已检查其运行中的资源使用情况。
 
### 挂起操作——加入挂起后的状态转变

　　活动就绪（原就绪状态）→ 静止就绪：进程不再被调度执行。（挂起）

　　活动阻塞（原阻塞状态）→ 静止阻塞。（挂起）

　　静止就绪 → 活动就绪。（激活）

　　静止阻塞 → 活动阻塞。（激活）

## 1.4进程同步

### 为什么需要同步？

　　进程的异步性会导致对共享变量或数据结构等资源不正确的访问次序，从而造成进程每次执行结果的不致，引发系统混乱。

　　为了杜绝这种差错，需对进程的执行次序进行协调，保证进程能按序执行。因此，需要引入进程的同步机制（例如：硬件同步机制、信号量机制、管程机制等）。

### 进程同步的基本概念

　　进程同步机制的主要任务：对多个相关进程在执行次序上进行协调，使并发执行。诸进程之间能按照一定的规则（或时序）共享系统资源，并能很好地相互合作，从而使程序的执行具有可再现性。

### 进程间的制约关系

　　多个进程之间由于共享系统资源或为完成某一任务而相互合作，它们之间可能存在着以下两种形式的制约关系：

　　**1.间接相互制约关系**

　　多个程序在并发执行时，由于共享系统资源，如CPU、IO设备等，致使在这些并发执行的程序之间形成相互制约的关系。对于像打印机、磁带机这样的临界资源，必须保证多个进程对之只能互斥地访问，由此，在这些进程间形成了源于对该类资源共享的所调间接相互制约关系。

　　**2.直接相互制约关系**

　　某些应用程序，为了完成某任务而建立了两个或多个进程。这些进程将为完成同一项任务而相互合作。进程间的直接制约关系就是源于它们之间的相互合作。例如，有两个相互合作的进程输入进程A和计算进程B，它们之间共享一个缓冲区。进程A通过缓冲向进程B提供数据。进程B从缓冲中取出数据，并对数据进行处理。但如果该缓冲空时，进程B因不能获得所需数据而被阻塞。一旦进程A把数据输入缓冲区后便将进程B唤反之，当缓冲区已满时，进程A因不能再向缓冲区投放数据而被阻塞，当进程B将缓冲区数据取走后便可唤醒A。

　　由于上述两种约束关系的存在，导致了进程运行的不可控制。而同步进制则是从这两点出发从而协调进程的执行次序。
## 1.5同步问题之生产者-消费者及临界区

### 生产者－消费者问题

　　生产者－消费者（ producer－consumer）问题是一个著名的进程同步问题。它描述的是一群生产者进程在生产产品，并将这些产品提供给消费者进程去消费。为使生产者进程与消费者进程能并发执行，在两者之间设置了一个具有n个缓冲区的级冲池，生产者进程将其所生产的产品放入一个缓冲区中：消费者进程可从一个缓冲区中取走产品去消费。尽管所有的生产者进程和消费者进程都是以异步方式运行的，但它们之间必须保持同步，既不允许消费者进程到一个空缓冲区去取产品，也不允许生产者进程向一个已装满产品且尚未被取走的缓冲区中投放产品。

　　同时我们可以使用一个整型共享变量counter记录缓冲池的产品数量。若生产者产出一个产品，那么count+1。消费者消费一个产品count-1。以此确定缓冲区的产品数量，而这两个操作在机器语言实现是常用以下形式表述：

```java
//生产者生产一个产品
register1=counter;//系统将内存中的counter值赋予寄存器1
register1++;//寄存器1自增
counter=register1；//将寄存器1的值赋回内存中的counter

//消费者消费一个产品
register2=counter;//系统将内存中的counter值赋予寄存器2
register2--;//寄存器2自减
counter=register2；//将寄存器2的值赋回内存中的counter
```

　　若当前counter值为1，生产者与消费者进程按照以上程序顺序执行，无论先后最终counter值应仍为1，结果美好。但并发时，进程是交替执行的，程序可能是以下这样执行的：
```java

register1=counter;//寄存器1值为1
register1++;//寄存器1值为2

register2=counter;//寄存器2值为1
register2--;//寄存器2值为0

counter=register1；//counter为2
counter=register2；//counter为0
```

　　明显可以看到由于进程执行顺序的不可控制（异步性）导致了结果的混乱。为了预防这种错误发生，我们需要对变量counter进行互斥访问控制。

### 临界区
　　由上述可知，不论是硬件临界资源还是软件临界资源，多个进程必须互斥地对它进
行访问。我们把在每个进程中访问临界资源的那段代码称为临界区。显然，若能保证诸进程互斥地进入自己的临界区，便可实现诸进程对临界资源的互斥访问。

　　为此，每个进程在进入临界区之前，应先对临界资源进行检査，看它是否正被访问。如果未被访问，进程便可进入临界区对该资源进行访问，并设置它正被访问的标志。如果正被访问，则本进程不能进入临界区。

　　因此，必须在临界区前面增加一段用于进行上述检查的代码，把这段代码称为进入区（ entry section）。相应地，在临界区后面也要加上一段称为退出区（ exit section）的代码，用于将临界区正被访问的标志恢复为未被访问的标志。这与Java中使用synchronized实现代码类似。
```java
synchronized (Lock){//进入区：临界资源检査，上锁
     代码块//临界区               
}//退出区，释放锁
```

### 同步机制应遵循的规则

- 空闲让进
- 忙则等待
- 有限等待：控制时间，避免陷入“死等”。
- 让权等待：进程若不能进入临界区时应释放CPU资源，以免陷入“忙等”。

## 1.6进程通信

　　进程通信是指进程之间的信息交换。由于进程的互斥与同步，需要在进程间交换一定的信息。

### 进程通信的类型

　　目前通信机制可归结为四大类：**共享存储器系统、管道通信系统、消息传递系统以及客户机－服务器系统。**

#### 共享存储系统

　　在共享存储器系统中，相互通信的进程共享某些数据结构或共享存储区，进程之间能够通过这些空间进行通信。

　　（1）基于共享数据结构的通信方式：在这种通信方式中，要求诸进程公用某些数据结构，借以实现诸进程间的信息交换，如在生产者－消费者问题中的有界缓冲区。

　　（2）基于共享存储区的通信方式：为了传输大量数据，在内存中划出了一块共享存储区域，诸进程可通过对该共享区的读或写交换信息，实现通信。

#### 管道（pipe）通信系统

　　所谓“管道”是指用于连接一个读进程和一个写进程以实现它们之间通信的一个共享文件，又名pipe文件。向管道（共享文件）提供输入的发送进程（即写进程）以字符流形式将大量的数据送入管道：而接受管道输出的接收进程（即读进程）则从管道中接收（读）数据。由于发送进程和接收进程是利用管道进行通信的，故又称为管道通信。

　　这种方式首创于UNX系统，由于它能有效地传送大量数据，因而又被引入到许多其它操作系统中。

#### 消息使递系统（ Message passing system）

　　在该机制中，进程不必借助任何共享存储区或数据结构，而是以格式化的消息为单位，将通信的数据封装在消息中，并利用操作系统提供的一组通信命令（原语），在进程间进行消息传递，完成进程间的数据交换。

　　该方式隐藏了通信实现细节，使通信过程对用户透明化，降低了通信程序设计的复杂性和错误率，成为当前应用最为广泛的一类进程间通信的机制。例如：在计算机网络中，消息（ message）又称为报文；在徹内核操作系统中，微内核与服务器之间的通信无一例外都是采用了消息传递机制。由于该机制能很好地支持多处理机系统、分布式系统和计算机网络，因此也成为这些领域最主要的通信工具。

　　消息传递系统的两种方式：

　　（1）直接通信方式：是指发送进程利用OS所提供的发送原语，直接把消息发送给目标进程。

　　（2）间接通信方式：是指发送和接收进程，都通过共享中间实体（称为邮箱）的方式进行消息的发送和接收，完成进程间的通信。

#### 客户机－服务器系统（ Client－ Server system）

　　前面所述的共享内存、消息传递等技术，虽然也可以用于实现不同计算机间进程的双向通信，但客户机一服务器系统的通信机制，在网络环境的各种应用领域已成为当前主流的通信实现机制，其主要的实现方法分为三类：套接字、远程过程调用和远程方法调用。

　　**套接字（ Socket）**

　　一个套接字就是一个通信标识类型的数据结构，包含了通信目的的地址、通信使用的端口号、通信网络的传输层协议、进程所在的网络地址，以及针对客户或服务器程序提供的不同系统调用（或API函数）等，是进程通信和网络通信的基本构件。

　　网络中的套接字通常采用的是非对称方式通信，即发送者需要提供接收者命名。通信双方的进程运行在不同主机的网络环境下，被分配了一对套接字，一个属于服务器端，一个属于客户端。一般地，客户端发出连接请求时，随机申请一个套接字，主机为之分配一个端口，与该套接字绑定，不再分配给其它进程。服务器端拥有全局公认的套接字和指定的端口（如ftp服务器监听端口为21，Web或http服务器监听端口为80），并通过监听端口等待客户请求。因此，任何进程都可以向它发出连接请求和信息请求，以方便进程之间建立连接。服务器端一且收到请求，就接受来自客户端的连接，完成连接后主机间传输的数据就可以准确地发送到通信进程，实现进程间的通信。当通信结束时，系统通过关闭接收服务器端的套接字撤销连接。

　　远程过程（或是方法）调用

　　远程过程（函数）调用RPC（ Remote Procedure Call），是一个通信协议，用于通过网络连接的系统，该协议允许运行于一台主机（本地）系统上的进程调用另一台主机（远程）系统上的进程，而对程序员表现为常规的过程调用，无需额外地为此编程。如果涉及的软件采用面向对象编程，那么远程过程调用亦可称做远程方法调用。

## 1.7线程基本概念

### 为什么要引入线程？

　　操作系统为了使多个程序并发执行引入了进程，以提高资源利用率和系统吞吐量。但是进程作为一个可拥有资源的独立单位，在创建、撤销、上下文切换时会付出较大的时间，空间上的开销。这就限制了系统所能设置进程的数量，而且进程切换也不宜太频繁，从而限制了并发程度。（进程“太重”了）

　　而引入线程，就是为了减少程序在并发执行时所付出的时空开销，使操作系统具有更好的并发性。

### 线程与进程的区别

　　线程具有许多传统进程所具有的特征，所以又称之为轻型进程（ Light－ WeighProcess）或进程元。下面我们从调度性、并发性、系统开销和拥有资源等方面对线程和进程进行比较。

#### 调度的基本单位

　　在传统的OS中，进程是作为独立调度和分派的基本单位，因而进程是能独立运行的基本单位。在每次被调度时，都需要进行上下文切换，开销较大。而在引入线程的OS中，已把线程作为调度和分派的基本单位，因而线程是能独立运行的基本单位。当线程切换时，仅需保存和设置少量寄存器内容，切换代价远低于进程。

　　在同一进程中，线程的切换不会引起进程的切換，但从一个进程中的线程切换到另一个进程中的线程时，必然就会引起进程的切换。
　　
#### 并发性

　　在引入线程的OS中，不仅进程之间可以并发执行，而且在一个进程中的多个线程之间亦可并发执行。同样，不同进程中的线程也能并发执行。这使得OS具有更好的并发性，从而能更加有效地提高系统资源的利用率和系统的吞吐量。

#### 拥有资源

　　进程可以拥有资源，并作为系统中有资源的一个基本单位。然面，线程本身并不拥有系统资源，而是仅有一点必不可少的、能保证独立运行的资源。比如，在每个线程中都应具有一个用于控制线程运行的线程控制块TCB、用于指示被执行指令序列的程序计数器保留局部变量、少数状态参数和返回地址等的一组寄存器和堆栈。线程除了拥有自己的少量资源外，还允许多个线程共享该进程所拥有的资源。

#### 独立性

　　在同一进程中的不同线程之间的独立性要比不同进程之间的独立性低得多。这是因为，为防止进程之间彼此干扰和破坏，每个进程都拥有一个独立的地址空间和其它资源，除了共享全局变量外，不允许其它进程的访问。

　　但是同一进程中的不同线程往往是为了提高并发性以及进行相互之间的合作而创建的，它们共享进程的内存地址空间和资源，如每个线程都可以访问它们所属进程地址空间中的所有地址，如一个线程的堆栈可以被其它线程读、写，甚至完全清除。

#### 系统开销

　　在创建或撤消进程时，系统都要为之分配和回收进程控制块、分配或回收其它资源，如内存空间和1O设各等。OS为此所付出的开销，明显大于线程创建或撤消时所付出的开销。同样在进程切换时，涉及到进程上下文的切换，而线程的切换代价也远低于进程。此外，由于一个进程中的多个线程具有相同的地址空间，线程之间的同步和通信也比进程的简单。

#### 支持多处理机系统

　　在多处理机系统中，对于传统的进程，即单线程进程，不管有多少处理机，该进程只能运行在一个处理机上。但对于多线程进程，就可以将一个进程中的多个线程分配到多个处理机上，使它们并行执行，这无疑将加速进程的完成。因此，现代多处理机OS都无不例外地引入了多线程。

## 2.1死锁的产生与处理

### 死锁的定义

　　如果一组进程中的每一个进程都在等待仅由该组进程中的其它进程才能引发的事件，么该组进程是死锁的（Deadlock）。

　　在一组进程发生死锁的情况下，这组死锁进程中的每一个进程，都在等待另一个死锁程所占有的资源。或者说每个进程所等待的事件是该组中其它进程释放所占有的资源。由于所有这些进程都已无法运行，因此它们谁也不能释放资源，致使没有任何一个进程被唤醒，这样这组进程只能无限期地等待下去。


### 产生死锁的必要条件

　　虽然进程在运行过程中可能会发生死锁，但产生进程死锁是必须具备一定条件的。综上所述不难看出，产生死锁必须同时具备下面四个必要条件，只要其中任一个条件不成立，死锁就不会发生：

　　**互斥条件**：进程对所分配到的资源进行排它性使用，即在一段时间内，某资源只能被一个进程占用。如果此时还有其它进程请求该资源，则请求进程只能等待，直至占有该资源的进程用毕释放。

　　**请求和保持条件**：进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源已被其它进程占有，此时请求进程被阻塞，但对自己已经获得的资源保持不放。

　　**不可抢占条件**：进程已获得的资源在未使用完之前不能被抢占，只能在进程使用完时由自己释放。

　　**循环等特条件**:在发生死锁时，必然存在一个进程一资源的循环链，即进程集合(P0，P1,P2,P3，... Pn）中的P0正在等待一个P1占用的资源，P1正在等待p2占用的资源,... Pn正在等待已被P0占用的资源。


### 处理死锁的方法

　　（1）**预防死锁**。这是一种较简单和直观的事先预防方法。该方法是通过设置某些限制条件，去**破坏产生死锁四个必要条件中的一个或几个来预防产生死锁**。预防死锁是一种较易实现的方法，已被广泛使用。

　　（2）**避免死锁**。同样是属于事先预防策略，但它并不是事先采取各种限制措施，去破坏产生死锁的四个必要条件，而是在资源的动态分配过程中，用某种方法防止系统进入不安全状态，从而可以避免发生死锁。

　　（3）**检测死锁**。这种方法无须事先采取任何限制性措施，允许进程在运行过程中发生死锁。但可通过检测机构及时地检测出死锁的发生，然后采取适当的措施，把进程从死锁中解脱出来。

　　（4）**解除死锁**。当检测到系统中已发生死锁时，就采取相应措施，将进程从死锁状态中解脱出来。常用的方法是撤消一些进程，回收它们的资源，将它们分配给已处于阻塞状态的进程，使其能继续运行。

　　上述的四种方法，从（1）到（4）对死锁的防范程度逐渐减弱，但对应的是资源利 用率的提高，以及进程因资源因素而阻塞的频度下降（即并发程度提高）。

## 2.2死锁的预防与避免

### 预防死锁

　　预防死锁的方法是通过**破坏产生死锁的四个必要条件中的一个或几个，以避免发生死锁**。由于互斥条件是非共享设备所必须的，不仅不能改变，还应加以保证，因此主要是破坏产生死锁的后三个条件。

#### 破坏“请求和保持”条件

　　为了能破坏“请求和保持”条件，系统必须保证做到：当一个进程在请求资源时，它不能持有不可抢占资源。该保证可通过如下两个不同的协议实现：

　　1．第一种协议该协议规定，所有进程在开始运行之前，必须一次性地申请其在整个运行过程中所需的全部资源。此时若系统有足够的资源分配给某进程，便可把其需要的所有资源分配给它。这样，该进程在整个运行期间，便不会再提出资源要求，从而破坏了“请求”条件。

　　第一种协议的优点是简单、易行且安全。但缺点也极其明显：

　　(1)资源被严重浪费，严重地恶化了资源的利用率。进程在开始运行时就一次性地占用了整个运行过程所需的全部资源，其中有些资源可能仅在运行初期或运行快结束时才使用，甚至根本不使用。

　　(2)使进程经常会发生饥饿现象。因为仅当进程在获得了其所需的全部资源后才能开始运行，这样就可能由于个别资源长期被其它进程占用，而致使等待该资源的进程迟迟不能开始运行，而个别资源有可能仅在进程运行到最后才需要，如打印机往往就是如此。

　　2．第二种协议该协议是对第一种协议的改进，它允许一个进程只获得运行初期所需的资源后，便开始运行。进程运行过程中再逐步释放已分配给自己的、且已用毕的全部资源，然后再请求新的所需资源。我们可以通过一个具体例子来说明，第二种协议比第一种协议要好。

　　例如有一个进程，它所要完成的任务是，先将数据从磁带上复制到磁盘文件上，然后对磁盘文件进行排序，最后把结果打印出来。在采用第一种协议时，进程必须在开始时就请求磁带机、磁盘文件和打印机。然而打印机仅在最后才会用到，既影响到其利用率，还会影响到其它进程的运行。此外，又如磁带机和磁盘文件虽然空闲，但因打印机已分配给其它进程，因而进程还需要等待。在采用第二种协议时，进程在开始时只需请求磁带机、磁盘文件，然后就可运行。等到全部磁带上的数据已复制到磁盘文件中并已排序好后，便可将磁带机和磁盘文件释放掉，再去请求磁盘文件和打印机。这不仅能使进程更快地完成任务，提高设备的利用率，还可减少进程发生饥饿的机率。

#### 破坏“不可抢占”条件

　　为了能破坏“不可抢占”条件，协议中规定，个已经保持了某些不可被抢占资源的进程，提出新的资源请求而不能得到满足时，它必须释放已经保持的所有资源，待以后需要时再重新申请。这意味着进程已占有的资源会被暂时地释放，或者说是被抢占了，从而破坏了“不可抢占”条件。

　　该方法实现起来比较复杂，且需付出很大的代价。因为一个不可抢占的资源如打印机、CD刻录机等在使用一段时间后被抢占，可能会造成进程前一阶段工作的失效，即使是采取了某些防范措施，也还会使进程前后两次运行的信息不连续。这种策略还可能因为反复地申请和释放资源致使进程的执行被无限地推迟，这不仅延长了进程的周转时间，而且也增加了系统开销，降低了系统吞吐量。

#### 破坏“循环等待”条件

　　一个能保证“循环等待”条件不成立的方法是，对系统所有资源类型进行线性排序，并赋予不同的序号。规定每个进程必须按序号递增的顺序请求资源。

　　这种预防死锁的策略与前两种策略比较，其资源利用率和系统昋吐量都有较明显的改善。但也存在下述问题：首先，为系统中各类资源所规定的序号必须相对稳定，这就限制了新类型设备的增加：其次，尽管在为资源的类型分配序号时，已经考虑到大多数作业在实际使用这些资源时的顺序，但也经常会发生这种情况：作业使用各类资源的顺序与系统规定的顺序不同，造成对资源的浪费。第三，为方便用户，系统对用户在编程时所施加的限制件应尽量少，然而这种按规定次序申请资源的方法必然会限制用户简单、自主地编程。


### 避免死锁

　　避免死锁同样是属于事先预防的策略，但并不是事先采取某种限制措施，破坏产生死锁的必要条件，而是在资源动态分配过程中，防止系统进入不安全状态，以避免发生死锁。这种方法所施加的限制条件较弱，可能获得较好的系统性能，目前常用此方法来避免发生死锁。

#### 安全状态

　　系统安全状态在死锁避免方法中，把系统的状态分为安全状态和不安全状态。当系统处于安全状态时，可避免发生死锁。反之，当系统处于不安全状态时，则可能进入到死锁状态。


　　在该方法中，允许进程动态地申请资源，但系统在进行资源分配之前，应先计算此次资源分配的安全性。若此次分配不会导致系统进入不安全状态，才可将资源分配给进程，否则令进程等待。所谓安全状态，是指系统能按照某种进程的推进顺序(P1,P2,...Pn)，为每个进程Pi分配其所需资源，直至满足每个进程对资源的最大需求，使每个进程都可顺利地完成。此时称(P1,P2,...Pn)为安全序列。如果系统无法找到这样一个安全序列，则称系统处于不安全状态。

　　虽然并非所有不安全状态都必然会转为死锁状态，但当系统进入不安全状态后，就有可能进入死锁状态。反之，只要系统处于安全状态，系统便不会进入死锁状态。因此，避免死锁的实质在于，系统在进行资源分配时，应使系统不进入不安全状态。

#### 银行家算法

　　利用银行家算法避免死锁最有代表性的避免死锁的算法是 Dijkstra的银行家算法。起这样的名字是由于该算法原本是为银行系统设计的，以确保银行在发放现金贷款时，不会发生不能满足所有客户需要的情况。在OS中也可用它来实现避免死锁。

　　为实现银行家算法，每一个新进程在进入系统时，它必须申明在运行过程中，可能需要每种资源类型的最大单元数目，其数目不应超过系统所拥有的资源总量。当进程请求组资源时，系统必须首先确定是否有足够的资源分配给该进程。若有，再进一步计算在将这些资源分配给进程后，是否会使系统处于不安全状态。如果不会，才将资源分配给它，否则让进程等待。

#### 银行家算法中的数据结构

　　为了实现银行家算法，在系统中必须设置这样四个数据结构，分别用来描述系统中可利用的资源、所有进程对资源的最大需求、系统中的资源分配，以及所有进程还需要多少可利用资源向量。 

　　(1)可利用的资源一维数组：Available。这是一个含有m个元素的数组，其中的每一个元素代表一类可利用的资源数目，其初始值是系统中所配置的该类全部可用资源的数目，其数值随该类资源的分配和回收而动态地改变。如果 Available[j]＝K，则表示系统中现有Rj类资源K个

　　(2)最大需求矩阵Max。这是一个n*m的矩阵，它定义了系统中n个进程中的每一个进程对m类资源的最大需求。如果Max[i,j]＝K，则表示进程i需要Rj类资源的最大数目为K。

　　(3)分配矩阵 Allocation。这也是一个n*m的矩阵，它定义了系统中每一类资源当前已分配给每一进程的资源数。如果 Allocation[i,j]＝K，则表示进程i当前已分得K个Rj类资源。

　　(4)需求矩阵Necd。这也是一个n*m的矩阵，用以表示每一个进程尚需的各类资源数。如果Need[i,j]＝K，则表示进程i还需要K个Rj类资源方能完成其任务。


　　上述三个矩阵间存在下述关系：

　　Need[i,j]=Max[i,j]-Allocation[i,j];

#### 银行家算法的实现

　　设Request i是进程Pi的申请向量,如果Request i[j]=K,则表示进程Pi需要K个Rj类型的资源。当Pi发出资源请求后，系统按下述步骤进行检查：

　　(1)如果Request i[j]<=Need[i,j],便转向步骤(2);否则认为出错,因为它所需要的资源数已经超过它所宣布的最大值。

　　(2)如果Request i[j]<=Available[i,j],便转向步骤(3);否则,表示尚无足够资源,Pi需等待。

　　(3)系统试探着把资源分配给进程Pi,并修改下面数据结构中的数值：

　　Available[j]=Available[j]-Request i[j];

　　Allocation[i,j]=Allocation[i,j]+Request i[j];

　　Need[i,j]=Need[i,j]-Request i[j];

　　(4)系统执行安全性算法,检查此次资源分配后系统是否处于安全状态。若安全,才正式将资源分配给进程Pi，以完成本次分配;否则,将本次的试探分配作废,恢复原来的资源分配状态,让进程Pi等待。
## 2.3死锁的检测与解除

　　如果在系统中，既不采取死锁预防描施，也未配有死锁避免算法，系统很可能会发生死锁。在这种情况下，系统应当提供两个算法：

　　（1）死锁检测算法。该方法用于检测系统状态，以确定系统中是否发生了死锁。

　　（2）死锁解除算法。当认定系统中已发生了死锁，利用该算法可将系统从死锁状态中解脱出来。
　　
### 死锁的检测

　　为了能对系统中是否已发生了死锁进行检测，在系统中必须：保存有关资源的请求和分配信息，和提供一种算法，它利用这些信息来检测系统是否已进入死锁状态。

### 死锁的解除

　　如果利用死锁检测算法检测出在系统中己发生了死锁，则应立即采取相应的措施，以解除死锁。最简单的处理措施就是立即通知操作员，请操作员来以人工方法处理死锁。另种措施则是利用死锁解除算法，把系统从死锁状态中解脱出来。常采用解除死锁的两种方法是

　　（1）抢占资源。从一个或多个进程中抢占足够数量的资源，分配给死锁进程，以解除死锁状态。

　　（2）终止（或撤消）进程。终止（或撤消）系统中的一个或多个死锁进程，直至打破循环环路，使系统从死锁状态解脱出来。

### 终止进程的方法

　　1）终止所有死锁进程

　　这是一种最简单的方法，即是终止所有的死锁进程，死锁自然也就解除了，但所付出的代价可能会很大。因为其中有些进程可能已经运行了很长时间，已接近结東，一旦被终止真可谓“功亏一蒉”，以后还得从头再来。还可能会有其它方面的代价。

　　2）逐个终止进程

　　稍微温和的方法是，按照某种顺序，逐个地终止进程，直至有足够的资源，以打破循环等待，把系统从死锁状态解脱出来为止。但该方法所付出的代价也可能很大。

　　稍微温和的方法是，按照某种顺序，逐个地终止进程，直至有足够的资源，以打破循环等待，把系统从死锁状态解脱出来为止。但该方法所付出的代价也可能很大。因为每终止一个进程，都需要用死锁检测算法确定系统死锁是否已经被解除，若未解除还需再终止另一个进程。另外，在采取逐个终止进程策略时，还涉及到应采用什么策略选择一个要终止的进程。选择策略最主要的依据是，为死锁解除所付出的“代价最小”。但怎么样才算是“代价最小”，很难有一个精确的度量。我们在此仅提供在选择被终止进程时应考虑的若干因素：

　　（1）进程的优先级的大小

　　（2）进程已执行了多少时间，还需要多少时间方能完成？

　　（3）进程在运行中已经使用资源的多少，以后还需要多少资源？

　　（4）进程的性质是交互式的还是批处理式的？

## 2.4自旋锁

### 为什么要引入自旋锁？

　　如前所述，在单CPU系统中，CPU在执行读一修改一写原语操作时，是具有原子性的，即在执行这些操作时不会被中断。保证原子性的基本方法是，在执行原语之前关中断，完成后再开中断。但是，在对称多处理机系统中，CPU在执行读一修改一写原语时，已不能再保证其操作的原子性。因为CPU所执行的读一修改一写原语操作通常都包含了若干条指令，因此需要执行多次总线操作。而在多处理机系统中，总线往往又是由多个处理机共享，它们是通过竞争来获取总线的。如果某CPU在执行原语的过程中由其它CPU争得了总线，就可能会导致该CPU与其它CPU对同一存储单元读一写操作的交又，造成混乱。

　　因此，在多处理机系统中，还必须引入对总线实现互斥的机制。于是，自旋锁机制也就应运而生，并已大量应用于对总线资源的竞争。当然，自旋锁机制并不局限于对总线资源的竞争

### 实现对总线互斥访问的方法

　　利用自旋锁实现对总线互斥访问的方法是：在总线上设置一个自旋锁，该锁最多只能被一个内核进程持有。当一个内核进程需要使用总线，对某个存储单元进行读写访问时，先请求自旋锁，以获得对总线的使用权。如果该锁被占用，那么这个进程就会一直进行“旋转”，循环测试锁的状态，直到自旋锁重新可用。如果锁未被占用，请求该锁的内核进程便能立刻得到它，并且继续执行，直到完成对指定存储单元的读写操作后，释放该锁。可见，自旋锁可以在任何时刻防止多个内核进程同时进入临界区，因此可有效地避免多处理机上并发运行的内核进程对总线资源的竞争。

### 自旋锁与信号量的主要差别

　　自旋锁与信号量的主要差别在于：自旋锁可避免调用进程阻塞。由于自旋锁使用者一般保持锁时间非常短，调用进程用“旋转”来取代进程切换。而我们知道进程切换需要花费一定开销，并且会使高速缓存失效，直接影响系统的性能，因此将自旋锁应用于对总线源的竞争，其效率远高于信号量机制，且在多处理器环境中非常方便。

　　显然，用自旋锁所保护的临界区一般都应比较短，否则，发出请求的多个CPU在锁被占用时，就会不断对锁进行循环测试，长时间忙等，浪费过多的CPU资源。

　　一般而言，如果对于被保护的共享资源仅在进程的上下文访问，或有共享设备，或调用进程所保护的临界区较大时，应使用信号量进行保护。但是如果被保护的共享资源需要计算机操作中断上下文访问，或调用进程所保护的临界区非常小，即对共享资源的访问时间非常短的情况下，就应使用自旋锁。

　　自旋锁保持期间是不可抢占的，而信号量和读写信号量保持期间是可以被抢占的。自旋锁只有在内核可抢占或SMP的情况下才真正需要，在单CPU且不可抢占的内核下，为防止中断处理中的并发操作，可简单采用关闭中断的方式，不需要自旋锁，此时自旋锁的所有操作都是空操作。

### 自旋锁的类型

　　使用自旋锁的基本形式为：

```java
　　pin_lock(&lock);
　　临界区代码；
　　in unlock(&lock):
```
　　常用的自旋锁有三种类型：普通自旋锁、读写自旋锁和大读者自旋锁。

　　（1）普通自旋锁：若是锁可用，则将自旋锁变量置为0，否则为1。该类自旋锁的使用不会影响当前处理机的中断状态，一般在临界区的代码在禁止中断情况下使用，或者不能被中断处理程序所执行。

　　（2）读写自旋锁：允许多个读者同时以只读的方式访问相同的共享数据结构，但是当一个写者正在更新这个数据结构时，不允许其它读者或写者访问。该类自旋锁较普通自旋锁允许更高的并发性，只要有一个读者拥有，写者就不能强占。每个读写自旋锁包括一个n位的读者计数和一个解锁标记。一般而言，在写者等待的情况下，新进的读者较写者更容易抢占该锁。

　　（3）大读者自旋锁：获取读锁时只需要对本地读锁进行加锁，开销很小；获取写锁时则必须锁住所有CPU上的读锁，代价较高。

## 2.5读-拷贝-修改锁(RCU锁)

### 为什么要引入读一拷贝一修改锁（RCU）？

　　不论是常见的读写问题，还是前面所介绍的读写自旋锁，都是允许多个进程同时读，但只要有一个写进程在写，便禁止所有读进程去读，使读者进入阻塞状态。如果写的时间非常长，将严重影响到多个读进程的工作。是否能改善这一情况呢？即使有写进程在写，读进程仍可以去读，不会引起读进程的阻塞。回答是肯定的，其解决方法是改变写进程对文件（共享数据结构）进行修改（写）的方式。此即，当某写进程要往某文件中写入数据时，它先读该文件，将文件的内容拷贝到一个副本上，以后只对副本上的内容进行修改。修改完成后，在适当时侯再将修改完后的文件全部写回去。

### RCU(Read-copy-update)锁

　　RCU锁用来解决读者一写者问题。对于被RCU保护的共享文件（数据结构），无论读者和写者，都是以读的方式对其进行访问的，对于读者而言，不需要获得任何锁就可以访问它，对于写者而言，在访问它时，先制作该文件的一个副本，只对副本上的内容进行修改，然后使用一个回调（ callback）机制，即向系统中一个称为垃圾收集器的机构注册一个回调函数。最后，在适当的时机，由垃圾收集器调用写者注册的回调函数，把指向原来数据的指针重新指向新的被修改的数据，完成最后的数据释放或修改操作。

### 写回时机

　　在RCU锁机构中，如何确定将修改后的内容写回的时机？显然，最好是在所有读者都已完成自己的读任务后再将修改后的文件写回。为此，每一个读者完成对共享文件的操作后，都必须向写者提供一个信号，表示它不再使用该数据结构。当所有的读者都已经发送信号之时，便是所有引用该共享文件的CPU都已退出对该共享数据的操作之时，也就是写者可以将修改后的文件写回之时。对于写者而言，从对副本修改完成后，到执行真正的写修改，中间有一段延退时间，称为写延迟期（ grace period）

### RCU锁的优点

　　RCU实际上是一种改进的读写自旋锁。它的主要优点表现为如下两方面：

　　（1）读者不会被阻塞。读者在访问被RCU保护的共享数据时不会被阻塞。这一方面极大地提高了读进程的运行效率，另一方面也使读者所在的CPU不会发生上下文切换，减少了处理机的开销。

　　（2）无需为共享文件（数据）设置同步机构。在采用该机制时，允许多个读者和一个或多个写者同时访问被保护的数据，无需为共享数据设置同步机构，因而读者没有什么同步开销，也不需要考虑死锁等问题。但是写者的同步开销却比较大，需要复制被修改的数据结构，延迟数据结构的释放，还必须使用某种锁机制，与其它写者的修改操作同步并行。

　　尽管RCU锁对读者带来了很大的好处，但RCU并不能完全替代读写自旋锁。如果读操作较多，而写操作很少，用RCU的确是利大于弊：反之，如果写比较多，对读者的性能提高可能不足以弥补给写者带来的损失，此时还是应当采用读写自旋锁。
